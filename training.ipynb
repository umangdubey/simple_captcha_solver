{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"training.ipynb","provenance":[],"mount_file_id":"16G7nCv4LmBNgniA-JCouM0rpNhhEUym2","authorship_tag":"ABX9TyNVIWH92tkUAav1yuKaSIyq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"4YGlNTCUyjvL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"status":"ok","timestamp":1596013087709,"user_tz":-330,"elapsed":9060,"user":{"displayName":"Umang Dubey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPsAdTXQlRsdcshNd758ht2tJecVmQD4wCT5ZOlQ=s64","userId":"14884594357150272812"}},"outputId":"5f64de2d-1be2-456a-e0b7-a1bfaa43a28c"},"source":["\n","!pip install helpers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting helpers\n","  Downloading https://files.pythonhosted.org/packages/c9/d8/c85a9dffe8a12a9a4c02aded04c21e2ac1c3c1f6e06913f19ef4fef96687/helpers-0.2.0-py3-none-any.whl\n","Installing collected packages: helpers\n","Successfully installed helpers-0.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5dUIY4Gey3iI","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596021073527,"user_tz":-330,"elapsed":1422,"user":{"displayName":"Umang Dubey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPsAdTXQlRsdcshNd758ht2tJecVmQD4wCT5ZOlQ=s64","userId":"14884594357150272812"}}},"source":["import imutils\n","import cv2\n","\n","\n","def resize_to_fit(image, width, height):\n","    \"\"\"\n","    A helper function to resize an image to fit within a given size\n","    :param image: image to resize\n","    :param width: desired width in pixels\n","    :param height: desired height in pixels\n","    :return: the resized image\n","    \"\"\"\n","\n","    # grab the dimensions of the image, then initialize\n","    # the padding values\n","    (h, w) = image.shape[:2]\n","\n","    # if the width is greater than the height then resize along\n","    # the width\n","    if w > h:\n","        image = imutils.resize(image, width=width)\n","\n","    # otherwise, the height is greater than the width so resize\n","    # along the height\n","    else:\n","        image = imutils.resize(image, height=height)\n","\n","    # determine the padding values for the width and height to\n","    # obtain the target dimensions\n","    padW = int((width - image.shape[1]) / 2.0)\n","    padH = int((height - image.shape[0]) / 2.0)\n","\n","    # pad the image then apply one more resizing to handle any\n","    # rounding issues\n","    image = cv2.copyMakeBorder(image, padH, padH, padW, padW,\n","        cv2.BORDER_REPLICATE)\n","    image = cv2.resize(image, (width, height))\n","\n","    # return the pre-processed image\n","    return image"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaCUzPIaxkEn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"status":"error","timestamp":1596021881853,"user_tz":-330,"elapsed":805090,"user":{"displayName":"Umang Dubey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPsAdTXQlRsdcshNd758ht2tJecVmQD4wCT5ZOlQ=s64","userId":"14884594357150272812"}},"outputId":"0b20b5a1-a43b-4b95-8488-41f13a78f2de"},"source":["import cv2\n","import pickle\n","import os.path\n","import numpy as np\n","from imutils import paths\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.layers.core import Flatten, Dense\n","#from helpers import resize_to_fit\n","\n","\n","LETTER_IMAGES_FOLDER = \"/content/drive/My Drive/Colab Notebooks/captcha breaker/extracted_letter_images\"\n","MODEL_FILENAME = \"cap/content/drive/My Drive/Colab Notebooks/captcha breaker/model file.hdf5\"\n","MODEL_LABELS_FILENAME = \"model_labels.dat\"\n","\n","\n","# initialize the data and labels\n","data = []\n","labels = []\n","\n","# loop over the input images\n","for image_file in paths.list_images(LETTER_IMAGES_FOLDER):\n","    # Load the image and convert it to grayscale\n","    image = cv2.imread(image_file)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # Resize the letter so it fits in a 20x20 pixel box\n","    image = resize_to_fit(image, 20, 20)\n","\n","    # Add a third channel dimension to the image to make Keras happy\n","    image = np.expand_dims(image, axis=2)\n","\n","    # Grab the name of the letter based on the folder it was in\n","    label = image_file.split(os.path.sep)[-2]\n","\n","    # Add the letter image and it's label to our training data\n","    data.append(image)\n","    labels.append(label)\n","\n","\n","# scale the raw pixel intensities to the range [0, 1] (this improves training)\n","data = np.array(data, dtype=\"float\") / 255.0\n","labels = np.array(labels)\n","\n","# Split the training data into separate train and test sets\n","(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels, test_size=0.25, random_state=0)\n","\n","# Convert the labels (letters) into one-hot encodings that Keras can work with\n","lb = LabelBinarizer().fit(Y_train)\n","Y_train = lb.transform(Y_train)\n","Y_test = lb.transform(Y_test)\n","\n","# Save the mapping from labels to one-hot encodings.\n","# We'll need this later when we use the model to decode what it's predictions mean\n","with open(MODEL_LABELS_FILENAME, \"wb\") as f:\n","    pickle.dump(lb, f)\n","\n","# Build the neural network!\n","model = Sequential()\n","\n","# First convolutional layer with max pooling\n","model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=(20, 20, 1), activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","# Second convolutional layer with max pooling\n","model.add(Conv2D(50, (5, 5), padding=\"same\", activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","\n","# Hidden layer with 500 nodes\n","model.add(Flatten())\n","model.add(Dense(500, activation=\"relu\"))\n","\n","# Output layer with 32 nodes (one for each possible letter/number we predict)\n","model.add(Dense(32, activation=\"softmax\"))\n","\n","# Ask Keras to build the TensorFlow model behind the scenes\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n","\n","\n","model.summary()\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-ccfad2416b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLETTER_IMAGES_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Load the image and convert it to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"5kyjy4qQygqq","colab_type":"code","colab":{}},"source":["# Train the neural network\n","model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=32, epochs=10, verbose=1)\n","\n","# Save the trained model to disk\n","model.save(MODEL_FILENAME)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mrio47WGyZmX","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}